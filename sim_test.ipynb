{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import metrics\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(imageA, imageB):\n",
    "\t# the 'Mean Squared Error' between the two images is the\n",
    "\t# sum of the squared difference between the two images;\n",
    "\t# NOTE: the two images must have the same dimension\n",
    "\terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "\terr /= float(imageA.shape[0] * imageA.shape[1])\n",
    "\t\n",
    "\t# return the MSE, the lower the error, the more \"similar\"\n",
    "\t# the two images are\n",
    "\treturn err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = cv2.imread('datasets/popup_Br_308.jpg')\n",
    "image2 = cv2.imread('datasets/medium_Br_308.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]), interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(image1, image2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = cv2.imread('datasets/popup_Br_308.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_img1 = cv2.calcHist([image1], [0, 1, 2], None, [256, 256, 256], [0, 256, 0, 256, 0, 256])\n",
    "hist_img1[255, 255, 255] = 0 #ignore all white pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.normalize(hist_img1, hist_img1, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = cv2.imread('datasets/medium_Br_308.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_img2 = cv2.calcHist([image2], [0, 1, 2], None, [256, 256, 256], [0, 256, 0, 256, 0, 256])\n",
    "hist_img2[255, 255, 255] = 0  #ignore all white pixels\n",
    "cv2.normalize(hist_img2, hist_img2, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_val = cv2.compareHist(hist_img1, hist_img2, cv2.HISTCMP_CORREL)\n",
    "print(f\"Similarity Score: \", round(metric_val, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural Similarity Index (SSIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = cv2.imread('datasets/popup_Br_308.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(10,10))\n",
    "\n",
    "ax1.imshow(image1, cmap = plt.cm.gray)\n",
    "ax2.imshow(image2, cmap = plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = cv2.imread('datasets/medium_Br_308.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]), interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image1.shape, image2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim(image1, image2, win_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image3 = cv2.imread('datasets/kpss_mohov.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image3 = cv2.resize(image3, (image1.shape[1], image1.shape[0]), interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image1.shape, image3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "image2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "image3_gray = cv2.cvtColor(image3, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_score = metrics.structural_similarity(image1_gray, image2_gray, full=True)\n",
    "print(f\"SSIM Score: \", round(ssim_score[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_score = metrics.structural_similarity(image1_gray, image3_gray, full=True)\n",
    "print(f\"SSIM Score: \", round(ssim_score[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Vector Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/11541154/checking-images-for-similarity-with-opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jales\\anaconda3\\envs\\cccp_projects\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CLIP Model...\n"
     ]
    }
   ],
   "source": [
    "# Load the OpenAI CLIP Model\n",
    "print('Loading CLIP Model...')\n",
    "model = SentenceTransformer('clip-ViT-B-32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# Next we compute the embeddings\n",
    "# To encode an image, you can use the following code:\n",
    "# from PIL import Image\n",
    "# encoded_image = model.encode(Image.open(filepath))\n",
    "image_names = list(glob.glob('./datasets/*.jpg'))\n",
    "print(\"Images:\", len(image_names))\n",
    "encoded_image = model.encode([Image.open(filepath) for filepath in image_names], batch_size=128, convert_to_tensor=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we run the clustering algorithm. This function compares images aganist \n",
    "# all other images and returns a list with the pairs that have the highest \n",
    "# cosine similarity score\n",
    "processed_images = util.paraphrase_mining_embeddings(encoded_image)\n",
    "NUM_SIMILAR_IMAGES = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding duplicate images...\n"
     ]
    }
   ],
   "source": [
    "# =================\n",
    "# DUPLICATES\n",
    "# =================\n",
    "print('Finding duplicate images...')\n",
    "# Filter list for duplicates. Results are triplets (score, image_id1, image_id2) and is scorted in decreasing order\n",
    "# A duplicate image will have a score of 1.00\n",
    "# It may be 0.9999 due to lossy image compression (.jpg)\n",
    "duplicates = [image for image in processed_images if image[0] >= 0.999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the top X duplicate images\n",
    "for score, image_id1, image_id2 in duplicates[0:NUM_SIMILAR_IMAGES]:\n",
    "    print(\"\\nScore: {:.3f}%\".format(score * 100))\n",
    "    print(image_names[image_id1])\n",
    "    print(image_names[image_id2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding near duplicate images...\n"
     ]
    }
   ],
   "source": [
    "# =================\n",
    "# NEAR DUPLICATES\n",
    "# =================\n",
    "print('Finding near duplicate images...')\n",
    "# Use a threshold parameter to identify two images as similar. By setting the threshold lower, \n",
    "# you will get larger clusters which have less similar images in it. Threshold 0 - 1.00\n",
    "# A threshold of 1.00 means the two images are exactly the same. Since we are finding near \n",
    "# duplicate images, we can set it at 0.99 or any number 0 < X < 1.00.\n",
    "threshold = 0.99\n",
    "near_duplicates = [image for image in processed_images if image[0] < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9213765859603882, 1, 4],\n",
       " [0.8219942450523376, 0, 3],\n",
       " [0.7337963581085205, 1, 2],\n",
       " [0.6786683797836304, 0, 4],\n",
       " [0.6598712801933289, 2, 4],\n",
       " [0.6223414540290833, 2, 3],\n",
       " [0.615389883518219, 0, 1],\n",
       " [0.6018456816673279, 1, 3],\n",
       " [0.577682375907898, 3, 4],\n",
       " [0.5667539238929749, 0, 2]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "near_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 92.138%\n",
      "./datasets\\medium_Br_308.jpg\n",
      "./datasets\\popup_Br_308.jpg\n",
      "\n",
      "Score: 82.199%\n",
      "./datasets\\kpss_mohov.jpg\n",
      "./datasets\\medium_kpss_mohov.jpg\n",
      "\n",
      "Score: 73.380%\n",
      "./datasets\\medium_Br_308.jpg\n",
      "./datasets\\medium_earth_palms.jpg\n",
      "\n",
      "Score: 67.867%\n",
      "./datasets\\kpss_mohov.jpg\n",
      "./datasets\\popup_Br_308.jpg\n",
      "\n",
      "Score: 65.987%\n",
      "./datasets\\medium_earth_palms.jpg\n",
      "./datasets\\popup_Br_308.jpg\n",
      "\n",
      "Score: 62.234%\n",
      "./datasets\\medium_earth_palms.jpg\n",
      "./datasets\\medium_kpss_mohov.jpg\n",
      "\n",
      "Score: 61.539%\n",
      "./datasets\\kpss_mohov.jpg\n",
      "./datasets\\medium_Br_308.jpg\n",
      "\n",
      "Score: 60.185%\n",
      "./datasets\\medium_Br_308.jpg\n",
      "./datasets\\medium_kpss_mohov.jpg\n",
      "\n",
      "Score: 57.768%\n",
      "./datasets\\medium_kpss_mohov.jpg\n",
      "./datasets\\popup_Br_308.jpg\n",
      "\n",
      "Score: 56.675%\n",
      "./datasets\\kpss_mohov.jpg\n",
      "./datasets\\medium_earth_palms.jpg\n"
     ]
    }
   ],
   "source": [
    "for score, image_id1, image_id2 in near_duplicates[0:NUM_SIMILAR_IMAGES]:\n",
    "    print(\"\\nScore: {:.3f}%\".format(score * 100))\n",
    "    print(image_names[image_id1])\n",
    "    print(image_names[image_id2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cccp_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
